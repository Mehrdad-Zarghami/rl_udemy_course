{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TimeLimit<OrderEnforcing<PassiveEnvChecker<CartPoleEnv<CartPole-v0>>>>>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = gym.make('CartPole-v0')\n",
    "e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.04985859,  0.0495961 ,  0.03638246, -0.00027351], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = e.reset() # it is random \n",
    "obs\n",
    "# Here, we reset the environment and obtained the first observation (we always need to reset\n",
    "# the newly created environment). As I said, the observation is four numbers, so let's check how\n",
    "# we can know this in advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The action_space field is of the Discrete type, so our actions will be just 0 or 1, where 0\n",
    "means pushing the platform to the left and 1 means to the right. The observation space is of\n",
    "Box(4,) , which means a vector of size 4 with values inside the [âˆ’inf, inf] interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mehrd\\anaconda3\\envs\\torch\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.05085051, -0.14602824,  0.03637699,  0.30366287], dtype=float32),\n",
       " 1.0,\n",
       " False,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.step(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we pushed our platform to the left by executing the action 0 and got the tuple of four\n",
    "elements: \n",
    " \n",
    "* A new observation, which is a new vector of four numbers  \n",
    "* A reward of 1.0   \n",
    "* The done flag with value False , which means that the episode is not over yet and we are more or less okay  \n",
    "* Extra information about the environment, which is an empty dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(e.action_space.sample())\n",
    "print(e.action_space.sample())\n",
    "print(e.action_space.sample())\n",
    "print(e.action_space.sample())\n",
    "print(e.action_space.sample())\n",
    "print(e.action_space.sample())\n",
    "print(e.action_space.sample())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.3074541e+00  3.1582259e+38 -2.2640420e-01 -2.1411217e+38]\n",
      "[-1.9448510e+00  1.7938538e+38  2.3863353e-01  3.3870768e+38]\n",
      "[1.9237388e+00 2.9939379e+37 2.1958783e-01 3.0823241e+38]\n",
      "[-2.1351635e+00  2.8346408e+38  3.5855076e-01  1.1654986e+37]\n",
      "[-5.4128319e-02  6.7715912e+37 -2.4070342e-01 -5.5553135e+37]\n",
      "[6.5979570e-01 1.1226958e+38 1.5964280e-01 1.2782051e+38]\n"
     ]
    }
   ],
   "source": [
    "print(e.observation_space.sample())\n",
    "print(e.observation_space.sample())\n",
    "print(e.observation_space.sample())\n",
    "print(e.observation_space.sample())\n",
    "print(e.observation_space.sample())\n",
    "print(e.observation_space.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method returned a random sample from the underlying space, which in the case of our\n",
    "Discrete action space means a random number of 0 or 1, and for the observation space\n",
    "means a random vector of four numbers. The random sample of the observation space may\n",
    "not look useful, and this is true, but the sample from the action space could be used when we\n",
    "are not sure how to perform an action. This feature is especially handy because you don't\n",
    "know any RL methods yet, but we still want to play around with the Gym environment. Now\n",
    "that you know enough to implement your first randomly behaving agent for CartPole, let's do\n",
    "it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode is done in 29 steps, and total reward was 29.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "if __name__ == \"__main__\":\n",
    "    env = gym.make(\"CartPole-v0\")\n",
    "    total_reward = 0.0\n",
    "    total_steps = 0\n",
    "    obs = env.reset()\n",
    "# Here, we created the environment and initialized the counter of steps and the reward accumulator. \n",
    "# On the last line, we reset the environment to obtain the first observation (which we will\n",
    "# not use, as our agent is stochastic)\n",
    "    while True:\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward , done, _, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        total_steps += 1\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "    print(f\"Episode is done in {total_steps} steps, and total reward was {total_reward}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mehrd\\anaconda3\\envs\\torch\\lib\\site-packages\\gym\\envs\\classic_control\\cartpole.py:177: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned terminated = True. You should always call 'reset()' once you receive 'terminated = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.13661607,  0.36407408,  0.22710562,  0.12744747], dtype=float32),\n",
       " 0.0,\n",
       " True,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
